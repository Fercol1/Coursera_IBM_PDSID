{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n",
    "\n",
    "# Watson Speech to Text Translator\n",
    "\n",
    "Estimated time needed: **25** minutes\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "-   Create Speech to Text Translator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "<p>In this notebook, you will learn to convert an audio file of an English speaker to text using a Speech to Text API. Then you will translate the English version to a Spanish version using a Language Translator API. <b>Note:</b> You must obtain the API keys and enpoints to complete the lab.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<h2>Table of Contents</h2>\n",
    "<ul>\n",
    "    <li><a href=\"#ref0\">Speech To Text</a></li>\n",
    "    <li><a href=\"#ref1\">Language Translator</a></li>\n",
    "    <li><a href=\"#ref2\">Exercise</a></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm_watson\n",
      "  Downloading ibm-watson-5.1.0.tar.gz (382 kB)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in c:\\anaconda\\lib\\site-packages (from ibm_watson) (2.24.0)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in c:\\anaconda\\lib\\site-packages (from ibm_watson) (2.8.1)\n",
      "Collecting websocket-client==0.48.0\n",
      "  Downloading websocket_client-0.48.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting ibm_cloud_sdk_core>=3.3.6\n",
      "  Downloading ibm-cloud-sdk-core-3.9.0.tar.gz (38 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python_dateutil>=2.5.3->ibm_watson) (1.15.0)\n",
      "Collecting PyJWT<3.0.0,>=2.0.1\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: ibm-watson, wget, ibm-cloud-sdk-core\n",
      "  Building wheel for ibm-watson (setup.py): started\n",
      "  Building wheel for ibm-watson (setup.py): finished with status 'done'\n",
      "  Created wheel for ibm-watson: filename=ibm_watson-5.1.0-py3-none-any.whl size=375445 sha256=a6e4be1cbe450b0a1bc76b078647f684eafaafb8cd91fe3afb2cf8ea5361a1bc\n",
      "  Stored in directory: c:\\users\\ferpi\\appdata\\local\\pip\\cache\\wheels\\e6\\e5\\cf\\9e0c46ec51165c2a61af7f2d4fdd91df9c96071bb51264c828\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9686 sha256=ed5a54175a3c6a5d67cf853f3a185a13ebe29a40ef1c9c0e783a24c4301262db\n",
      "  Stored in directory: c:\\users\\ferpi\\appdata\\local\\pip\\cache\\wheels\\bd\\a8\\c3\\3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "  Building wheel for ibm-cloud-sdk-core (setup.py): started\n",
      "  Building wheel for ibm-cloud-sdk-core (setup.py): finished with status 'done'\n",
      "  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.9.0-py3-none-any.whl size=59616 sha256=15b36030572f5479428812c147b5159b374677a69fda422c144ddbf0351dc565\n",
      "  Stored in directory: c:\\users\\ferpi\\appdata\\local\\pip\\cache\\wheels\\f4\\58\\84\\3059fe7cfcadfa9c709fe5979a1cd6f79ff82e047c5f0d01bd\n",
      "Successfully built ibm-watson wget ibm-cloud-sdk-core\n",
      "Installing collected packages: websocket-client, PyJWT, ibm-cloud-sdk-core, ibm-watson, wget\n",
      "Successfully installed PyJWT-2.1.0 ibm-cloud-sdk-core-3.9.0 ibm-watson-5.1.0 websocket-client-0.48.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "#you will need the following library \n",
    "!pip install ibm_watson wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"ref0\">Speech to Text</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First we import <code>SpeechToTextV1</code> from <code>ibm_watson</code>.For more information on the API, please click on this <a href=\"https://cloud.ibm.com/apidocs/speech-to-text?code=python\">link</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1 \n",
    "import json\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The service endpoint is based on the location of the service instance, we store the information in the variable URL. To find out which URL to use, view the service credentials and paste the url here.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_s2t = \"https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/da25ca29-9d2f-4032-a3cc-d6a2c102061e\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You require an API key, and you can obtain the key on the <a href=\"https://cloud.ibm.com/resources\">Dashboard </a>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "iam_apikey_s2t = \"sDR6puO3tgSurfSIy9i-QKNcC2PA_024TwiG9BAIOc5h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You create a <a href=\"http://watson-developer-cloud.github.io/python-sdk/v0.25.0/apis/watson_developer_cloud.speech_to_text_v1.html\">Speech To Text Adapter object</a> the parameters are the  endpoint and API key.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter at 0x220fb518730>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authenticator = IAMAuthenticator(iam_apikey_s2t)\n",
    "s2t = SpeechToTextV1(authenticator=authenticator)\n",
    "s2t.set_service_url(url_s2t)\n",
    "s2t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lets download the audio file that we will use to convert into text.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-05-04 15:53:20--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/PolynomialRegressionandPipelines.mp3\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4234179 (4,0M) [audio/mpeg]\n",
      "Saving to: 'PolynomialRegressionandPipelines.mp3'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  326K 13s\n",
      "    50K .......... .......... .......... .......... ..........  2%  622K 9s\n",
      "   100K .......... .......... .......... .......... ..........  3% 1,59M 7s\n",
      "   150K .......... .......... .......... .......... ..........  4%  867K 6s\n",
      "   200K .......... .......... .......... .......... ..........  6%  749K 6s\n",
      "   250K .......... .......... .......... .......... ..........  7% 1,49M 5s\n",
      "   300K .......... .......... .......... .......... ..........  8%  873K 5s\n",
      "   350K .......... .......... .......... .......... ..........  9% 1,47M 5s\n",
      "   400K .......... .......... .......... .......... .......... 10%  518K 5s\n",
      "   450K .......... .......... .......... .......... .......... 12%  850K 5s\n",
      "   500K .......... .......... .......... .......... .......... 13% 1,66M 5s\n",
      "   550K .......... .......... .......... .......... .......... 14%  807K 4s\n",
      "   600K .......... .......... .......... .......... .......... 15% 1,38M 4s\n",
      "   650K .......... .......... .......... .......... .......... 16%  819K 4s\n",
      "   700K .......... .......... .......... .......... .......... 18%  948K 4s\n",
      "   750K .......... .......... .......... .......... .......... 19%  797K 4s\n",
      "   800K .......... .......... .......... .......... .......... 20%  637K 4s\n",
      "   850K .......... .......... .......... .......... .......... 21% 1,73M 4s\n",
      "   900K .......... .......... .......... .......... .......... 22%  779K 4s\n",
      "   950K .......... .......... .......... .......... .......... 24%  714K 4s\n",
      "  1000K .......... .......... .......... .......... .......... 25% 1,01M 4s\n",
      "  1050K .......... .......... .......... .......... .......... 26%  688K 4s\n",
      "  1100K .......... .......... .......... .......... .......... 27%  901K 4s\n",
      "  1150K .......... .......... .......... .......... .......... 29%  548K 4s\n",
      "  1200K .......... .......... .......... .......... .......... 30%  650K 4s\n",
      "  1250K .......... .......... .......... .......... .......... 31%  232K 4s\n",
      "  1300K .......... .......... .......... .......... .......... 32%  540K 4s\n",
      "  1350K .......... .......... .......... .......... .......... 33% 1,36M 4s\n",
      "  1400K .......... .......... .......... .......... .......... 35%  844K 4s\n",
      "  1450K .......... .......... .......... .......... .......... 36% 1014K 4s\n",
      "  1500K .......... .......... .......... .......... .......... 37%  997K 3s\n",
      "  1550K .......... .......... .......... .......... .......... 38%  690K 3s\n",
      "  1600K .......... .......... .......... .......... .......... 39% 1018K 3s\n",
      "  1650K .......... .......... .......... .......... .......... 41%  725K 3s\n",
      "  1700K .......... .......... .......... .......... .......... 42% 1,58M 3s\n",
      "  1750K .......... .......... .......... .......... .......... 43%  976K 3s\n",
      "  1800K .......... .......... .......... .......... .......... 44%  856K 3s\n",
      "  1850K .......... .......... .......... .......... .......... 45% 1,62M 3s\n",
      "  1900K .......... .......... .......... .......... .......... 47%  762K 3s\n",
      "  1950K .......... .......... .......... .......... .......... 48% 1,03M 3s\n",
      "  2000K .......... .......... .......... .......... .......... 49%  720K 3s\n",
      "  2050K .......... .......... .......... .......... .......... 50%  708K 3s\n",
      "  2100K .......... .......... .......... .......... .......... 51%  935K 3s\n",
      "  2150K .......... .......... .......... .......... .......... 53% 1,77M 2s\n",
      "  2200K .......... .......... .......... .......... .......... 54%  936K 2s\n",
      "  2250K .......... .......... .......... .......... .......... 55%  902K 2s\n",
      "  2300K .......... .......... .......... .......... .......... 56% 1,36M 2s\n",
      "  2350K .......... .......... .......... .......... .......... 58%  763K 2s\n",
      "  2400K .......... .......... .......... .......... .......... 59% 1,36M 2s\n",
      "  2450K .......... .......... .......... .......... .......... 60%  512K 2s\n",
      "  2500K .......... .......... .......... .......... .......... 61% 1,48M 2s\n",
      "  2550K .......... .......... .......... .......... .......... 62%  794K 2s\n",
      "  2600K .......... .......... .......... .......... .......... 64%  889K 2s\n",
      "  2650K .......... .......... .......... .......... .......... 65%  679K 2s\n",
      "  2700K .......... .......... .......... .......... .......... 66%  665K 2s\n",
      "  2750K .......... .......... .......... .......... .......... 67% 1,06M 2s\n",
      "  2800K .......... .......... .......... .......... .......... 68%  578K 2s\n",
      "  2850K .......... .......... .......... .......... .......... 70% 1,00M 2s\n",
      "  2900K .......... .......... .......... .......... .......... 71%  926K 1s\n",
      "  2950K .......... .......... .......... .......... .......... 72% 1,18M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 73%  546K 1s\n",
      "  3050K .......... .......... .......... .......... .......... 74% 1,00M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 76%  625K 1s\n",
      "  3150K .......... .......... .......... .......... .......... 77%  547K 1s\n",
      "  3200K .......... .......... .......... .......... .......... 78%  789K 1s\n",
      "  3250K .......... .......... .......... .......... .......... 79% 1,26M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 81%  580K 1s\n",
      "  3350K .......... .......... .......... .......... .......... 82% 1,01M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 83%  562K 1s\n",
      "  3450K .......... .......... .......... .......... .......... 84%  785K 1s\n",
      "  3500K .......... .......... .......... .......... .......... 85% 1,41M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 87%  917K 1s\n",
      "  3600K .......... .......... .......... .......... .......... 88%  795K 1s\n",
      "  3650K .......... .......... .......... .......... .......... 89% 1,44M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 90% 1010K 0s\n",
      "  3750K .......... .......... .......... .......... .......... 91% 1,06M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 93% 1,40M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 94%  974K 0s\n",
      "  3900K .......... .......... .......... .......... .......... 95% 1,62M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 96% 1,05M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 97%  742K 0s\n",
      "  4050K .......... .......... .......... .......... .......... 99% 1,64M 0s\n",
      "  4100K .......... .......... .......... ....                 100% 1,63M=4,9s\n",
      "\n",
      "2021-05-04 15:53:26 (837 KB/s) - 'PolynomialRegressionandPipelines.mp3' saved [4234179/4234179]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O PolynomialRegressionandPipelines.mp3  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/PolynomialRegressionandPipelines.mp3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have the path of the wav file we would like to convert to text</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method recognize in module ibm_watson.speech_to_text_v1:\n",
      "\n",
      "recognize(audio: <class 'BinaryIO'>, *, content_type: str = None, model: str = None, language_customization_id: str = None, acoustic_customization_id: str = None, base_model_version: str = None, customization_weight: float = None, inactivity_timeout: int = None, keywords: List[str] = None, keywords_threshold: float = None, max_alternatives: int = None, word_alternatives_threshold: float = None, word_confidence: bool = None, timestamps: bool = None, profanity_filter: bool = None, smart_formatting: bool = None, speaker_labels: bool = None, customization_id: str = None, grammar_name: str = None, redaction: bool = None, audio_metrics: bool = None, end_of_phrase_silence_time: float = None, split_transcript_at_phrase_end: bool = None, speech_detector_sensitivity: float = None, background_audio_suppression: float = None, **kwargs) -> ibm_cloud_sdk_core.detailed_response.DetailedResponse method of ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter instance\n",
      "    Recognize audio.\n",
      "    \n",
      "    Sends audio and returns transcription results for a recognition request. You can\n",
      "    pass a maximum of 100 MB and a minimum of 100 bytes of audio with a request. The\n",
      "    service automatically detects the endianness of the incoming audio and, for audio\n",
      "    that includes multiple channels, downmixes the audio to one-channel mono during\n",
      "    transcoding. The method returns only final results; to enable interim results, use\n",
      "    the WebSocket API. (With the `curl` command, use the `--data-binary` option to\n",
      "    upload the file for the request.)\n",
      "    **See also:** [Making a basic HTTP\n",
      "    request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http#HTTP-basic).\n",
      "    ### Streaming mode\n",
      "     For requests to transcribe live audio as it becomes available, you must set the\n",
      "    `Transfer-Encoding` header to `chunked` to use streaming mode. In streaming mode,\n",
      "    the service closes the connection (status code 408) if it does not receive at\n",
      "    least 15 seconds of audio (including silence) in any 30-second period. The service\n",
      "    also closes the connection (status code 400) if it detects no speech for\n",
      "    `inactivity_timeout` seconds of streaming audio; use the `inactivity_timeout`\n",
      "    parameter to change the default of 30 seconds.\n",
      "    **See also:**\n",
      "    * [Audio\n",
      "    transmission](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#transmission)\n",
      "    *\n",
      "    [Timeouts](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#timeouts)\n",
      "    ### Audio formats (content types)\n",
      "     The service accepts audio in the following formats (MIME types).\n",
      "    * For formats that are labeled **Required**, you must use the `Content-Type`\n",
      "    header with the request to specify the format of the audio.\n",
      "    * For all other formats, you can omit the `Content-Type` header or specify\n",
      "    `application/octet-stream` with the header to have the service automatically\n",
      "    detect the format of the audio. (With the `curl` command, you can specify either\n",
      "    `\"Content-Type:\"` or `\"Content-Type: application/octet-stream\"`.)\n",
      "    Where indicated, the format that you specify must include the sampling rate and\n",
      "    can optionally include the number of channels and the endianness of the audio.\n",
      "    * `audio/alaw` (**Required.** Specify the sampling rate (`rate`) of the audio.)\n",
      "    * `audio/basic` (**Required.** Use only with narrowband models.)\n",
      "    * `audio/flac`\n",
      "    * `audio/g729` (Use only with narrowband models.)\n",
      "    * `audio/l16` (**Required.** Specify the sampling rate (`rate`) and optionally the\n",
      "    number of channels (`channels`) and endianness (`endianness`) of the audio.)\n",
      "    * `audio/mp3`\n",
      "    * `audio/mpeg`\n",
      "    * `audio/mulaw` (**Required.** Specify the sampling rate (`rate`) of the audio.)\n",
      "    * `audio/ogg` (The service automatically detects the codec of the input audio.)\n",
      "    * `audio/ogg;codecs=opus`\n",
      "    * `audio/ogg;codecs=vorbis`\n",
      "    * `audio/wav` (Provide audio with a maximum of nine channels.)\n",
      "    * `audio/webm` (The service automatically detects the codec of the input audio.)\n",
      "    * `audio/webm;codecs=opus`\n",
      "    * `audio/webm;codecs=vorbis`\n",
      "    The sampling rate of the audio must match the sampling rate of the model for the\n",
      "    recognition request: for broadband models, at least 16 kHz; for narrowband models,\n",
      "    at least 8 kHz. If the sampling rate of the audio is higher than the minimum\n",
      "    required rate, the service down-samples the audio to the appropriate rate. If the\n",
      "    sampling rate of the audio is lower than the minimum required rate, the request\n",
      "    fails.\n",
      "     **See also:** [Audio\n",
      "    formats](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formats#audio-formats).\n",
      "    ### Multipart speech recognition\n",
      "     **Note:** The Watson SDKs do not support multipart speech recognition.\n",
      "    The HTTP `POST` method of the service also supports multipart speech recognition.\n",
      "    With multipart requests, you pass all audio data as multipart form data. You\n",
      "    specify some parameters as request headers and query parameters, but you pass JSON\n",
      "    metadata as form data to control most aspects of the transcription. You can use\n",
      "    multipart recognition to pass multiple audio files with a single request.\n",
      "    Use the multipart approach with browsers for which JavaScript is disabled or when\n",
      "    the parameters used with the request are greater than the 8 KB limit imposed by\n",
      "    most HTTP servers and proxies. You can encounter this limit, for example, if you\n",
      "    want to spot a very large number of keywords.\n",
      "    **See also:** [Making a multipart HTTP\n",
      "    request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http#HTTP-multi).\n",
      "    \n",
      "    :param BinaryIO audio: The audio to transcribe.\n",
      "    :param str content_type: (optional) The format (MIME type) of the audio.\n",
      "           For more information about specifying an audio format, see **Audio formats\n",
      "           (content types)** in the method description.\n",
      "    :param str model: (optional) The identifier of the model that is to be used\n",
      "           for the recognition request. See [Languages and\n",
      "           models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models#models).\n",
      "    :param str language_customization_id: (optional) The customization ID\n",
      "           (GUID) of a custom language model that is to be used with the recognition\n",
      "           request. The base model of the specified custom language model must match\n",
      "           the model specified with the `model` parameter. You must make the request\n",
      "           with credentials for the instance of the service that owns the custom\n",
      "           model. By default, no custom language model is used. See [Custom\n",
      "           models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#custom-input).\n",
      "           **Note:** Use this parameter instead of the deprecated `customization_id`\n",
      "           parameter.\n",
      "    :param str acoustic_customization_id: (optional) The customization ID\n",
      "           (GUID) of a custom acoustic model that is to be used with the recognition\n",
      "           request. The base model of the specified custom acoustic model must match\n",
      "           the model specified with the `model` parameter. You must make the request\n",
      "           with credentials for the instance of the service that owns the custom\n",
      "           model. By default, no custom acoustic model is used. See [Custom\n",
      "           models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#custom-input).\n",
      "    :param str base_model_version: (optional) The version of the specified base\n",
      "           model that is to be used with the recognition request. Multiple versions of\n",
      "           a base model can exist when a model is updated for internal improvements.\n",
      "           The parameter is intended primarily for use with custom models that have\n",
      "           been upgraded for a new base model. The default value depends on whether\n",
      "           the parameter is used with or without a custom model. See [Base model\n",
      "           version](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#version).\n",
      "    :param float customization_weight: (optional) If you specify the\n",
      "           customization ID (GUID) of a custom language model with the recognition\n",
      "           request, the customization weight tells the service how much weight to give\n",
      "           to words from the custom language model compared to those from the base\n",
      "           model for the current request.\n",
      "           Specify a value between 0.0 and 1.0. Unless a different customization\n",
      "           weight was specified for the custom model when it was trained, the default\n",
      "           value is 0.3. A customization weight that you specify overrides a weight\n",
      "           that was specified when the custom model was trained.\n",
      "           The default value yields the best performance in general. Assign a higher\n",
      "           value if your audio makes frequent use of OOV words from the custom model.\n",
      "           Use caution when setting the weight: a higher value can improve the\n",
      "           accuracy of phrases from the custom model's domain, but it can negatively\n",
      "           affect performance on non-domain phrases.\n",
      "           See [Custom\n",
      "           models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#custom-input).\n",
      "    :param int inactivity_timeout: (optional) The time in seconds after which,\n",
      "           if only silence (no speech) is detected in streaming audio, the connection\n",
      "           is closed with a 400 error. The parameter is useful for stopping audio\n",
      "           submission from a live microphone when a user simply walks away. Use `-1`\n",
      "           for infinity. See [Inactivity\n",
      "           timeout](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#timeouts-inactivity).\n",
      "    :param List[str] keywords: (optional) An array of keyword strings to spot\n",
      "           in the audio. Each keyword string can include one or more string tokens.\n",
      "           Keywords are spotted only in the final results, not in interim hypotheses.\n",
      "           If you specify any keywords, you must also specify a keywords threshold.\n",
      "           Omit the parameter or specify an empty array if you do not need to spot\n",
      "           keywords.\n",
      "           You can spot a maximum of 1000 keywords with a single request. A single\n",
      "           keyword can have a maximum length of 1024 characters, though the maximum\n",
      "           effective length for double-byte languages might be shorter. Keywords are\n",
      "           case-insensitive.\n",
      "           See [Keyword\n",
      "           spotting](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#keyword_spotting).\n",
      "    :param float keywords_threshold: (optional) A confidence value that is the\n",
      "           lower bound for spotting a keyword. A word is considered to match a keyword\n",
      "           if its confidence is greater than or equal to the threshold. Specify a\n",
      "           probability between 0.0 and 1.0. If you specify a threshold, you must also\n",
      "           specify one or more keywords. The service performs no keyword spotting if\n",
      "           you omit either parameter. See [Keyword\n",
      "           spotting](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#keyword_spotting).\n",
      "    :param int max_alternatives: (optional) The maximum number of alternative\n",
      "           transcripts that the service is to return. By default, the service returns\n",
      "           a single transcript. If you specify a value of `0`, the service uses the\n",
      "           default value, `1`. See [Maximum\n",
      "           alternatives](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#max_alternatives).\n",
      "    :param float word_alternatives_threshold: (optional) A confidence value\n",
      "           that is the lower bound for identifying a hypothesis as a possible word\n",
      "           alternative (also known as \"Confusion Networks\"). An alternative word is\n",
      "           considered if its confidence is greater than or equal to the threshold.\n",
      "           Specify a probability between 0.0 and 1.0. By default, the service computes\n",
      "           no alternative words. See [Word\n",
      "           alternatives](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#word_alternatives).\n",
      "    :param bool word_confidence: (optional) If `true`, the service returns a\n",
      "           confidence measure in the range of 0.0 to 1.0 for each word. By default,\n",
      "           the service returns no word confidence scores. See [Word\n",
      "           confidence](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#word_confidence).\n",
      "    :param bool timestamps: (optional) If `true`, the service returns time\n",
      "           alignment for each word. By default, no timestamps are returned. See [Word\n",
      "           timestamps](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#word_timestamps).\n",
      "    :param bool profanity_filter: (optional) If `true`, the service filters\n",
      "           profanity from all output except for keyword results by replacing\n",
      "           inappropriate words with a series of asterisks. Set the parameter to\n",
      "           `false` to return results with no censoring. Applies to US English\n",
      "           transcription only. See [Profanity\n",
      "           filtering](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#profanity_filter).\n",
      "    :param bool smart_formatting: (optional) If `true`, the service converts\n",
      "           dates, times, series of digits and numbers, phone numbers, currency values,\n",
      "           and internet addresses into more readable, conventional representations in\n",
      "           the final transcript of a recognition request. For US English, the service\n",
      "           also converts certain keyword strings to punctuation symbols. By default,\n",
      "           the service performs no smart formatting.\n",
      "           **Note:** Applies to US English, Japanese, and Spanish transcription only.\n",
      "           See [Smart\n",
      "           formatting](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#smart_formatting).\n",
      "    :param bool speaker_labels: (optional) If `true`, the response includes\n",
      "           labels that identify which words were spoken by which participants in a\n",
      "           multi-person exchange. By default, the service returns no speaker labels.\n",
      "           Setting `speaker_labels` to `true` forces the `timestamps` parameter to be\n",
      "           `true`, regardless of whether you specify `false` for the parameter.\n",
      "           **Note:** Applies to US English, Australian English, German, Japanese,\n",
      "           Korean, and Spanish (both broadband and narrowband models) and UK English\n",
      "           (narrowband model) transcription only.\n",
      "           See [Speaker\n",
      "           labels](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#speaker_labels).\n",
      "    :param str customization_id: (optional) **Deprecated.** Use the\n",
      "           `language_customization_id` parameter to specify the customization ID\n",
      "           (GUID) of a custom language model that is to be used with the recognition\n",
      "           request. Do not specify both parameters with a request.\n",
      "    :param str grammar_name: (optional) The name of a grammar that is to be\n",
      "           used with the recognition request. If you specify a grammar, you must also\n",
      "           use the `language_customization_id` parameter to specify the name of the\n",
      "           custom language model for which the grammar is defined. The service\n",
      "           recognizes only strings that are recognized by the specified grammar; it\n",
      "           does not recognize other custom words from the model's words resource. See\n",
      "           [Grammars](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#grammars-input).\n",
      "    :param bool redaction: (optional) If `true`, the service redacts, or masks,\n",
      "           numeric data from final transcripts. The feature redacts any number that\n",
      "           has three or more consecutive digits by replacing each digit with an `X`\n",
      "           character. It is intended to redact sensitive numeric data, such as credit\n",
      "           card numbers. By default, the service performs no redaction.\n",
      "           When you enable redaction, the service automatically enables smart\n",
      "           formatting, regardless of whether you explicitly disable that feature. To\n",
      "           ensure maximum security, the service also disables keyword spotting\n",
      "           (ignores the `keywords` and `keywords_threshold` parameters) and returns\n",
      "           only a single final transcript (forces the `max_alternatives` parameter to\n",
      "           be `1`).\n",
      "           **Note:** Applies to US English, Japanese, and Korean transcription only.\n",
      "           See [Numeric\n",
      "           redaction](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#redaction).\n",
      "    :param bool audio_metrics: (optional) If `true`, requests detailed\n",
      "           information about the signal characteristics of the input audio. The\n",
      "           service returns audio metrics with the final transcription results. By\n",
      "           default, the service returns no audio metrics.\n",
      "           See [Audio\n",
      "           metrics](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics#audio_metrics).\n",
      "    :param float end_of_phrase_silence_time: (optional) If `true`, specifies\n",
      "           the duration of the pause interval at which the service splits a transcript\n",
      "           into multiple final results. If the service detects pauses or extended\n",
      "           silence before it reaches the end of the audio stream, its response can\n",
      "           include multiple final results. Silence indicates a point at which the\n",
      "           speaker pauses between spoken words or phrases.\n",
      "           Specify a value for the pause interval in the range of 0.0 to 120.0.\n",
      "           * A value greater than 0 specifies the interval that the service is to use\n",
      "           for speech recognition.\n",
      "           * A value of 0 indicates that the service is to use the default interval.\n",
      "           It is equivalent to omitting the parameter.\n",
      "           The default pause interval for most languages is 0.8 seconds; the default\n",
      "           for Chinese is 0.6 seconds.\n",
      "           See [End of phrase silence\n",
      "           time](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#silence_time).\n",
      "    :param bool split_transcript_at_phrase_end: (optional) If `true`, directs\n",
      "           the service to split the transcript into multiple final results based on\n",
      "           semantic features of the input, for example, at the conclusion of\n",
      "           meaningful phrases such as sentences. The service bases its understanding\n",
      "           of semantic features on the base language model that you use with a\n",
      "           request. Custom language models and grammars can also influence how and\n",
      "           where the service splits a transcript. By default, the service splits\n",
      "           transcripts based solely on the pause interval.\n",
      "           See [Split transcript at phrase\n",
      "           end](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-output#split_transcript).\n",
      "    :param float speech_detector_sensitivity: (optional) The sensitivity of\n",
      "           speech activity detection that the service is to perform. Use the parameter\n",
      "           to suppress word insertions from music, coughing, and other non-speech\n",
      "           events. The service biases the audio it passes for speech recognition by\n",
      "           evaluating the input audio against prior models of speech and non-speech\n",
      "           activity.\n",
      "           Specify a value between 0.0 and 1.0:\n",
      "           * 0.0 suppresses all audio (no speech is transcribed).\n",
      "           * 0.5 (the default) provides a reasonable compromise for the level of\n",
      "           sensitivity.\n",
      "           * 1.0 suppresses no audio (speech detection sensitivity is disabled).\n",
      "           The values increase on a monotonic curve. See [Speech Activity\n",
      "           Detection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#detection).\n",
      "    :param float background_audio_suppression: (optional) The level to which\n",
      "           the service is to suppress background audio based on its volume to prevent\n",
      "           it from being transcribed as speech. Use the parameter to suppress side\n",
      "           conversations or background noise.\n",
      "           Specify a value in the range of 0.0 to 1.0:\n",
      "           * 0.0 (the default) provides no suppression (background audio suppression\n",
      "           is disabled).\n",
      "           * 0.5 provides a reasonable level of audio suppression for general usage.\n",
      "           * 1.0 suppresses all audio (no audio is transcribed).\n",
      "           The values increase on a monotonic curve. See [Speech Activity\n",
      "           Detection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#detection).\n",
      "    :param dict headers: A `dict` containing the request headers\n",
      "    :return: A `DetailedResponse` containing the result, headers and HTTP status code.\n",
      "    :rtype: DetailedResponse with `dict` result representing a `SpeechRecognitionResults` object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename='PolynomialRegressionandPipelines.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We create the file object <code>wav</code> with the wav file using  <code>open</code> ; we set the <code>mode</code> to  \"rb\" ,  this is similar to read mode, but it ensures the file is in binary mode.We use the method <code>recognize</code> to return the recognized text. The parameter audio is the file object <code>wav</code>, the parameter <code>content_type</code> is the format of the audio file.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(filename, mode=\"rb\")  as wav:\n",
    "    response = s2t.recognize(audio=wav, content_type='audio/mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The attribute result contains a dictionary that includes the translation:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result_index': 0,\n",
       " 'results': [{'final': True,\n",
       "   'alternatives': [{'transcript': 'in this video we will cover polynomial regression and pipelines ',\n",
       "     'confidence': 0.94}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"what do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code \",\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function \",\n",
       "     'confidence': 0.95}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'the model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation ',\n",
       "     'confidence': 0.95}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"there also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear \",\n",
       "     'confidence': 0.91}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"let's look at an example from our data we generate a polynomial regression model \",\n",
       "     'confidence': 0.89}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'in python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression ',\n",
       "     'confidence': 0.92}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"negative one point five five seven X. one cute plus two hundred four point eight X. one squared plus eight thousand nine hundred sixty five X. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example \",\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that I mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate X. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline ',\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well ',\n",
       "     'confidence': 0.89}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'the method normalizes the data performs a polynomial transform then outputs a prediction ',\n",
       "     'confidence': 0.89}]}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in this video we will cover polynomial regress...</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what do we do when a linear model is not the b...</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polynomial regression is a special case of the...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the model can be cubic which means the predict...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there also exists higher order polynomial regr...</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>let's look at an example from our data we gene...</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in python we do this by using the poly fit fun...</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative one point five five seven X. one cute...</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>consider the feature shown here applying the m...</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pipeline sequentially perform a series of tran...</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the method normalizes the data performs a poly...</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           transcript  confidence\n",
       "0   in this video we will cover polynomial regress...        0.94\n",
       "1   what do we do when a linear model is not the b...        0.90\n",
       "2   polynomial regression is a special case of the...        0.95\n",
       "3   the model can be cubic which means the predict...        0.95\n",
       "4   there also exists higher order polynomial regr...        0.91\n",
       "5   let's look at an example from our data we gene...        0.89\n",
       "6   in python we do this by using the poly fit fun...        0.92\n",
       "7   negative one point five five seven X. one cute...        0.90\n",
       "8   consider the feature shown here applying the m...        0.90\n",
       "9   pipeline sequentially perform a series of tran...        0.89\n",
       "10  the method normalizes the data performs a poly...        0.89"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import json_normalize\n",
    "\n",
    "json_normalize(response.result['results'],\"alternatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x220fb4e3b20>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can obtain the recognized text and assign it to the variable <code>recognized_text</code>:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_text=response.result['results'][0][\"alternatives\"][0][\"transcript\"]\n",
    "type(recognized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"ref1\">Language Translator</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First we import <code>LanguageTranslatorV3</code> from ibm_watson. For more information on the API click <a href=\"https://cloud.ibm.com/apidocs/speech-to-text?code=python\"> here</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import LanguageTranslatorV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The service endpoint is based on the location of the service instance, we store the information in the variable URL. To find out which URL to use, view the service credentials.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url_lt='https://api.us-south.language-translator.watson.cloud.ibm.com/instances/d4f55ce6-1641-4a95-9232-226119fd3348'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You require an API key, and you can obtain the key on the <a href=\"https://cloud.ibm.com/resources\">Dashboard</a>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "apikey_lt='JSoJuQ7mBU9eT_QOUDw_Yxc4GKWq_fQu1578NsoSlrZF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>API requests require a version parameter that takes a date in the format version=YYYY-MM-DD. This lab describes the current version of Language Translator, 2018-05-01</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "version_lt='2018-05-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>we create a  Language Translator object <code>language_translator</code>:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_watson.language_translator_v3.LanguageTranslatorV3 at 0x220fc28b280>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authenticator = IAMAuthenticator(apikey_lt)\n",
    "language_translator = LanguageTranslatorV3(version=version_lt,authenticator=authenticator)\n",
    "language_translator.set_service_url(url_lt)\n",
    "language_translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can get a Lists the languages that the service can identify.\n",
    "The method Returns the language code.  For example English (en) to  Spanis (es) and name of each language.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>Azerbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba</td>\n",
       "      <td>Bashkir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>Belarusian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>uk</td>\n",
       "      <td>Ukrainian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ur</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vi</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>zh</td>\n",
       "      <td>Simplified Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>Traditional Chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   language                 name\n",
       "0        af            Afrikaans\n",
       "1        ar               Arabic\n",
       "2        az          Azerbaijani\n",
       "3        ba              Bashkir\n",
       "4        be           Belarusian\n",
       "..      ...                  ...\n",
       "71       uk            Ukrainian\n",
       "72       ur                 Urdu\n",
       "73       vi           Vietnamese\n",
       "74       zh   Simplified Chinese\n",
       "75    zh-TW  Traditional Chinese\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import json_normalize\n",
    "\n",
    "json_normalize(language_translator.list_identifiable_languages().get_result(), \"languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can use the method <code>translate</code> this will translate the text. The parameter text is the text. Model_id is the type of model we would like to use use we use list the language . In this case, we set it to 'en-es' or English to Spanish. We get a Detailed Response object translation_response</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x220fb33ae50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_response = language_translator.translate(\\\n",
    "    text=recognized_text, model_id='en-es')\n",
    "translation_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The result is a dictionary.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translations': [{'translation': 'en este vdeo cubriremos la regresin polinmica y las tuberas '}],\n",
       " 'word_count': 10,\n",
       " 'character_count': 64}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation=translation_response.get_result()\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can obtain the actual translation as a string as follows:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en este vdeo cubriremos la regresin polinmica y las tuberas '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_translation =translation['translations'][0]['translation']\n",
    "spanish_translation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can translate back to English</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_new = language_translator.translate(text=spanish_translation ,model_id='es-en').get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can obtain the actual translation as a string as follows:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in this video we will cover the polynomial regression and the pipes '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_eng=translation_new['translations'][0]['translation']\n",
    "translation_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Quiz</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate to French.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x220fb518580>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below and press Shift+Enter to execute\n",
    "translation_response2 = language_translator.translate(\\\n",
    "    text=recognized_text, model_id='en-fr')\n",
    "translation_response2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translations': [{'translation': 'Dans cette vido, nous couvrons la rgression polynomiale et les pipelines '}],\n",
       " 'word_count': 10,\n",
       " 'character_count': 64}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_french=translation_response2.get_result()\n",
    "translation_french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dans cette vido, nous couvrons la rgression polynomiale et les pipelines '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_translation =translation_french['translations'][0]['translation']\n",
    "french_translation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "French_translation=language_translator.translate(\n",
    "    text=translation_eng , model_id='en-fr').get_result()\n",
    "\n",
    "French_translation['translations'][0]['translation']\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Language Translator</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>References</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://cloud.ibm.com/apidocs/speech-to-text?code=python](https://cloud.ibm.com/apidocs/speech-to-text?code=python&utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork-19487395)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://cloud.ibm.com/apidocs/language-translator?code=python](https://cloud.ibm.com/apidocs/language-translator?code=python&utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork-19487395)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors:\n",
    "\n",
    " [Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork-19487395) \n",
    "\n",
    "Joseph Santarcangelo has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
    "\n",
    "## Other Contributor(s)\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/fanjiang0619/\">Fan Jiang</a>\n",
    "\n",
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n",
    "| ----------------- | ------- | ---------- | ---------------------------------- |\n",
    "| 2021-04-07        | 2.2     | Malika     | Updated the libraries              |\n",
    "| 2021-01-05        | 2.1     | Malika     | Added a library                    |\n",
    "| 2020-08-26        | 2.0     | Lavanya    | Moved lab to course repo in GitLab |\n",
    "|                   |         |            |                                    |\n",
    "|                   |         |            |                                    |\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## <h3 align=\"center\">  IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
